\chapter{An Issue of Trust}
\label{chap:trust}

Trust and privacy are closely related qualities in
computing~\cite{flowerday2006}. Can we maintain our digital privacy
without having to trust anyone? We can imagine scenarios that maintain
privacy without trust, but they generally involve only storing data on
self-designed, built, and programmed devices that never leave our
possession. Such arrangements are, at best, impractical for the vast
majority of users, and at worst, simply not possible to achieve
today. The range of manufactures, suppliers, and service providers
inherent in the modern computing landscape require that we make
decisions regarding whom to trust at every step of any digital
interaction in which we partake.

The cloud computing model, by its very nature, further amplifies the
number of parties we must trust. But what does it mean to trust a
third party in the cloud? Before discussing the details of an SSaaS
ecosystem, it's helpful to further define ``trust''. In this chapter,
I define a model for analyzing trust and apply this model to compare
various traditional software and technology deployments to SSaaS-backed
options.

\section{Analyses Framework}
\label{chap:trust:framework}

Generally, when we use modern computing devices and services, we must
trust third-party manufactures and service providers with our
data. The manner in which this third party trust relates to the
privacy of user data has two main factors: how much trust do we place
in third parties (e.g. how much of our personal data do we grant them
access to), and in what manner can they violate this trust (e.g. how
can they abuse the access they are granted). I will thus evaluate
computing trust models across two main axes: the \emph{degree} of
trust we must place in third parties, and the manner in which this
trust might be \emph{violated}. Our ideal trust model for a given use
case will minimize the degree of third party trust while also
minimizing the likelihood that such trust will be violated.

In terms of degrees of trust, we can entrust third parties with the
following data-related capabilities:

\begin{packed_desc}
\item[Storage (S):] \hfill \\
  Can a third party faithfully store private user data and make it
  available to the user upon request? Misuse of this capability may
  result in a loss of user data, but won't generally result in the
  exposure of user data.
\item[Access (R):] \hfill \\
  Can a third party read and interpret the private user data they
  store? Misuse of this capability may result in the exposure of user
  data.
\item[Manipulation (W):] \hfill \\ Can a third party modify the
  private user data to which they have access? Misuse of this
  capability may result in the ability to manipulate a user
  (e.g. changing appointments on a user's calendar, etc).
\item[Meta-analysis (M):] \hfill \\
  Can a third party gather user metadata related to any stored private
  user data? Misuse of this capability may result in the ability to
  infer private user data (e.g. who a user is friends with based on
  data sharing patterns).
\end{packed_desc}

I'll define a trust violation as occurring when a third party
exercises any of the above capabilities without explicit user
knowledge and permission. Put another way, a trust violation occurs
whenever a third party leverages a capability with which they are
entrusted in a manner in which the user does not expect the capability
to be leveraged.

I define several types of trust violations based on the manner in
which the violation occurs and the motivations behind it:

\begin{packed_desc}
\item[Implicit (P):] \hfill \\
  This class of trust violation occurs when a third party violates a
  user's trust in a manner approved by the third party. An example
  might be sharing user data with a business partner (e.g. an
  advertiser). Often these forms of violations aren't really
  ``violations'' in the sense that a user may have clicked though a
  Terms of Service agreement that granted implicit permission for such
  use, but if the third party is engaging in behavior that the user
  would not generally expect, an implicit trust violation has
  occurred.
\item[Compelled (C):] \hfill \\
  This class of trust violation occurs when a third party is compelled
  by another actor to violate a user's trust. The most common example
  would be a third party being forced to turn over user data or
  records in response to a request from the government with
  jurisdiction over the party.
\item[Unintentional (U):] \hfill \\
  This form of violation occurs when a third party unintentionally
  discloses or manipulates user data. An example would be a coding
  error that allows either the loss of or unfettered access to user
  data.
\item[Insider (I):] \hfill \\
  This class of violation occurs when a privileged adversary within
  the third party violates a user's trust without the permission or
  knowledge of the third party. An example would be a cloud service
  provider employee accessing or disclosing private user data without
  authorization.
\item[Outsider (O):] \hfill \\
  This class of violation occurs when an external adversary gains
  unauthorized access to private user data stored by third party. An
  example would be an adversary exploiting a bug in a third party's
  authorization infrastructure to gain unauthorized access to user
  data.
\end{packed_desc}

\section{Traditional Model}
\label{chap:trust:traditional}

\begin{figure}[t]
  \centering
  \includegraphics[height=175px]{./figs/out/TrustModel-Traditional.pdf}
  \caption{Traditional Trust Model}
  \label{fig:trust-traditional}
\end{figure}

Existing cloud services are not generally well optimized for
maximizing user privacy. Such services tend to apply an all-or-nothing
trust model where a user must seed a high degree of trust to each
service in order to reap the benefits each service provides. Figure
\ref{fig:trust-traditional} shows the basic trust-for-features
relationship between a user, their private data, and a traditional
cloud service provider.

We can analyze the Dropbox example from \S~\ref{chap:intro:example}
using my proposed framework. To begin, what capabilities is a normal
Dropbox user entrusting to Dropbox? Clearly, users must trust Dropbox
to faithfully store their data since that is Dropbox's core purpose,
so we have granted Dropbox the \emph{S} capability. Furthermore users
must also grant Dropbox the ability to read and access their data
(i.e. the \emph{R} capability) in order to support Dropbox's sharing
and syncing features. While Dropbox doesn't generally utilize it,
users are also effectively granting the manipulation (\emph{W})
capability as well since the user has no mechanisms for ensuring that
Dropbox can't manipulate their data. Finally, Dropbox has full access
to user metadata related to their usage of the service, granting them
the \emph{M} capability. Thus, Dropbox users must trust Dropbox with
all possible capabilities.

But how likely is it that Dropbox might misuse any of these
capabilities, thus violating the user's trust and privacy? In terms of
implicit violations (\emph{I}), Dropbox charges users for storage, and
thus shouldn't generally rely on reading or sharing user data for
advertising purposes. Furthermore, such a business model relies on
Dropbox remaining in its paying users' good graces, disincentivizing
potentially questionable behavior. None the less, there is evidence of
Dropbox opening user files for unknown
reasons~\cite{vintsurf-dropbox}, which might indicate a possible
\emph{I} violation. The user has no way to prevent an \emph{I}
violation when using Dropbox, so we can do no more than give Dropbox
the benefit of the doubt in this area.

In terms of compelled (\emph{C}) violations, Dropbox is a US-based
company, and is thus susceptible to a variety of government-sponsored
data requested, from subpoenas issued under the Third Party
Doctrine~\cite{thompson-thirdparty}, to probable cause search
warrants~\cite{us-constitution-amend4}, to National Security
Letters~\cite{fbi-nsl}, to FISC~\cite{fisc} orders. Dropbox publishes
a transparency report~\cite{dropbox-transparency} indicating how
frequently they are compelled to violate user privacy. Recent versions
of this report indicate that Dropbox receives a few hundred requests
for various user data every 6 months.

Unintentional (\emph{U}), Insider (\emph{I}), or Outsider (\emph{O})
violations are all possibilities when using Dropbox. On the \emph{U}
front, Dropbox had an incident in 2011 that allowed anyone to log into
the service using any password for a 5 hour
period~\cite{dropbox-authbug}. Thus far, Dropbox appears to have
avoided any \emph{I}-type violations, but it has been the target of
various \emph{O}-type attempted violations, primarily built around
advisories who obtain common user
passwords~\cite{dropbox-passwords}. Needless to say, while Dropbox
works to avoid these kinds of violations, they are certainly still
possible, have occurred in the past, and may well occur in the future.

As we can see, a traditional cloud service like Dropbox currently
requires an essentially full degree of user trust (i.e. \emph{S},
\emph{R}, \emph{W}, and \emph{M} capabilities) while also being
susceptible to a full range of trust violations (e.g. \emph{P},
\emph{C}, \emph{U}, \emph{I}, and \emph{O} type violations). Dropbox
is not unique. Other modern computing services from social media
sites, to file lockers, to communication systems all suffer from the
same high-trust, high potential for violations paradigm.

\section{SSaaS Model}
\label{chap:trust:ssaas}

\begin{figure}[t]
  \centering
  \includegraphics[height=175px]{./figs/out/TrustModel-Seperated.pdf}
  \caption{SSaaS Trust Model}
  \label{fig:trust-ssaas}
\end{figure}

In order to enhance user privacy in the cloud, we must move beyond the
traditional full-trust, easily violated model presented in
\S~\ref{chap:trust:traditional}. Of the two components of my trust
framework, degree of trust and potential for violation, degree is the
easier to control quality: what capabilities to trust a cloud provider
with is largely within the user's control, where as the method in
which trust might be violated is largely outside of a user's
control. I will thus focus my solution on mitigating degree of trust
first while disincentivizing methods of violation second.

The ideal trust model begins with the principle of least
privilege~\cite{saltzer1975}: we should only afford a cloud provider
the minimal degree of trust necessary to provide the intended
features. Furthermore, in order to monitor cloud providers for
potential trust violations, we would also like to maintain some degree
of auditing over any capability we entrust to a provider. Minimal,
audited trust is the basis of my ideal trust model.

Applying this ideal trust model to the previous Dropbox example, I
conclude that Dropbox should really only be afforded the storage
(\emph{S}) capability: after all, there is no real need for Dropbox to
ever be able to access (\emph{R}) or manipulate (\emph{W}) user data
in order to blindly sync files across device or share them with other
users. While Dropbox does not need the metadata (\emph{M}) capability
to simply support the desired user case, it is far more difficult for
the user to limit this capability then the \emph{R} or \emph{W}
capabilities. I thus will also concede this capability to Dropbox as
well. We have thus reduced Dropbox's capabilities from four (full
trust) to two (minimal trust).

But how can we enforce this limited trust profile when using Dropbox?
Figure~\ref{fig:trust-ssaas} shows my proposed SSaaS solution to this
problem. I introduce a new actor: the Secret Storage Provider (SSP)
into the mix. I then restrict the user to only storing encrypted and
authenticated data with Dropbox. The user stores the associated
encryption and verification keys with the SSP. Assuming we utilize
strong encryption and integrity systems like AES~\cite{nist2001} +
CMAC~\cite{dworkin2005}, Dropbox can not feasibly decrypt and access
the user's data nor can they manipulate user data without
detection. Storing the keys with an SSP, as opposed to simply forcing
the user to maintain them manually, has a number of benefits: namely,
it affords users continued support for simple sharing and syncing use
cases. As long as the user's Dropbox client can communicate with the
SSP from any location where they can also communicate with Dropbox,
the user can continue to utilize Dropbox as they traditionally would,
but with significantly less trust in Dropbox itself.

But have we simply replaced one third party with another? Why is the
SSP any more trustworthy than Dropbox itself? There are several reason
why we might expect an SSP to be less prone to trust violations then a
feature provider like Dropbox. I'll discuss these in
\S\ref{chap:ssaas}. But in terms of degrees of trust, we really aren't
affording the SSP any greater degree of trust then Dropbox. Both are
entrusted with the \emph{S} and \emph{M} capabilities, but neither has
the \emph{R} or \emph{W} capability: Dropbox has limited capabilities
because it only holds encrypted and authenticated user data, and the
SSP has limited capabilities because it holds no direct user data at
all, only the cryptographic keys used to protect such data. As long as
the SSP faithfully guards the secret keys they store, the trust model
holds. There are a few new risks in the SSaaS model, however. If both
the feature provider (e.g. Dropbox) and the SSP are located in the
same regulatory jurisdiction, it may still be possible for a single
entity to compel (\emph{C}-type violation) them both or provide data
that would allow an adversary to elevate their capabilities to include
\emph{R} and \emph{W}. Likewise, if Dropbox and the SSP collude to
violate a user's trust, a similar capability elevation will
occur. This latter point introduces a new violation type into my
framework:

\begin{packed_desc}
\item[Colluding (L):] \hfill \\ This class of violation occurs when
  multiple partially-trusted parties collude to gain capabilities over
  user data beyond what the user intended each individually to
  have. An example would be an SSP sharing the user's encryption keys
  with the feature provider storing the corresponding encrypted data.
\end{packed_desc}

This framework provided a basis for analyzing third party trust as
well as the basic argument in favor of SSaaS as a trust-reducing
system. I discuss SSP trust and violation mitigation further in
Chapter~\ref{chap:ssaas}.

\section{Trust Survey of Existing Systems}
\label{chap:trust:survey}

In order to evaluate the trust and security of the SSaaS ecosystem,
it's useful to apply this trust model to a number of existing
scenarios. Table~\ref{tab:trust:app:cap} shows a summery of the
capabilities granted to third parties across a number of common
applications. Table~\ref{tab:trust:app:threats} shows known and likely
threats posed by third parties across the same range of
applications. Each of these applications is discussed in more depth
below.

\begin{table}[!th]
  \footnotesize
  \centering
  \tabulinesep = 2pt
  \begin{tabu} to \textwidth
    { | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | }
    \hline
    \textbf{Application}
    & \textbf{Storage}
    & \textbf{Access}
    & \textbf{Manipulation}
    & \textbf{Meta-analysis}
    \\ \hline
    Dropbox
    & Full
    & Full
    & Full
    & Full
    \\ \hline
    Tresorit
    & Full
    & Partial
    & Partial
    & Full
    \\ \hline
    Facebook
    & Full
    & Full
    & Full
    & Full
    \\ \hline
    Gmail
    & Full
    & Full
    & Full
    & Full
    \\ \hline
    PGP/GPG
    & Full
    & None
    & None
    & Full
    \\ \hline
    Hangouts
    & Full
    & Full
    & Full
    & Full
    \\ \hline
    TextSecure
    & Full
    & None
    & None
    & Minimal
    \\ \hline 
    LastPass
    & Full
    & Minimal
    & Full
    & Full
    \\ \hline 
 \end{tabu}
  \caption[Third Party Trust Capabilities]{
    Third Party Trust Capabilities\\
    \textit{(Least Trust) None, Minimal, Partial, Full (Most Trust)}
  }
  \label{tab:trust:app:cap}
\end{table}

\begin{table}[!th]
  \footnotesize
  \centering
  \tabulinesep = 2pt
  \begin{tabu} to \textwidth
    { | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | }
    \hline
    \textbf{Application}
    & \textbf{Implicit}
    & \textbf{Compelled}
    & \textbf{Unintended}
    & \textbf{Insider}
    & \textbf{Outsider}
    & \textbf{Colluding}
    \\ \hline
    Dropbox
    & Desincent.
    & Known
    & Desincent.
    & Desincent.
    & Desincent.
    & N/A
    \\ \hline
    Tresorit
    & Desincent.
    & Vulnerable
    & Desincent.
    & Desincent.
    & Desincent.
    & N/A
    \\ \hline
    Facebook
    & Known
    & Known
    & Desincent.
    & Desincent.
    & Desincent.
    & N/A
    \\ \hline
    Gmail
    & Vulnerable
    & Known
    & Desincent.
    & Desincent.
    & Desincent.
    & N/A
    \\ \hline
    PGP/GPG
    & N/A
    & N/A
    & Mitigated
    & Mitigated
    & Mitigated
    & N/A
    \\ \hline
    Hangouts
    & Vulnerable
    & Known
    & Desincent.
    & Desincent.
    & Desincent.
    & N/A
    \\ \hline
    TextSecure
    & Disincent.
    & Disincent.
    & Mitigated
    & Mitigated
    & Mitigated
    & N/A
    \\ \hline
    LastPass
    & Disincent.
    & Vulnerable
    & Disincent.
    & Disincent.
    & Disincent.
    & N/A
    \\ \hline
  \end{tabu}
  \caption[Third Party Trust Violations]{
    Third Party Trust Violations\\
    \textit{(Least Likely) Minimized, Mitigated, Disincentivized, Vulnerable, Known (Most Likely)}
  }
  \label{tab:trust:app:threats}
\end{table}

\subsection{Cloud File Storage}

As mentioned, cloud file storage is a popular third party use
case. I've discussed Dropbox~\cite{dropbox} as an example cloud
storage provider extensively in the earlier sections of this
chapter. A summery of the Dropbox trust model results are shown the
Tables~\ref{tab:trust:app:cap} and~\ref{tab:trust:app:threats}. As
previously concluded, Dropbox both requires a full range of trusted
capabilities and is susceptible to a full range of violations this
trust. Google Drive~\cite{google-drive}, Microsoft
OneDrive~\cite{microsoft-onedrive}, and related services have similar
trust profiles to Dropbox.

As discussed in Chapter~\ref{chap:related}, a number of systems have
been developed with the aim of overcoming the trust challenges. These
systems include ``end-to-end'' encrypted file storage services such as
Tresorit~\cite{tresorit}. These systems aim to place limits on a their
own ability to leverage the access (\emph{R}) capability through the
use of client-side encryption. Likewise, they aim to limit their
access to the manipulation (\emph{W}) capability through client-side
data authentication. In the base case where a user merely wishes to
store data on a single device and not share it with others, these
systems are fairly successful in achieving their desired trust
mitigations. In order to sync data across multiple devices using such
systems, a user must manually provide some secret (e.g. a password,
etc) on each device to bootstrap its operation. While potentially
burdensome and inconvenient, this practice is in line with these
services trusted capabilities mitigation since it does not require any
additional third party trust.

The place where these systems falter at mitigating third party trust
is via their support for multi-user sharing and collaboration. Such
services tend to accomplish multi-user sharing by acting as a trusted
certificate authority (CA) in charge of issuing user
certificates\footnote{A certificate is a combination of a user's
  public key and certain metadata signed by a trusted issuers. See
  Section~\ref{chap:background:crypto} for more information.} These
certificates are then used with various asymmetric cryptographic
primitives (e.g. RSA~\cite{rivest1978}) to exchange the necessary
secrets between users and bootstrap secure multi-user
sharing. Unfortunately, as a trusted CA, these services are capable of
issuing fraudulent user certificates to themselves or other
parties. This allows them to mount man-in-the-middle (MitM) attacks on
any user trying to share data by impersonating other users utilizing
the services. This deficiency is discussed in depth
at~\cite{wilson2014}, and leads to a breakdown of their claim that
their users need not trust such service providers themselves, at least
when employing multi-user sharing. By mounting a MitM attack on a user
trying to share data with another user, such service providers can
regain the \emph{R} and \emph{W} capabilities they claim not to
have. Furthermore, these services do little to mitigate their access
to metadata (\emph{M} capability). Nor do they provide ways for users
to avoid data loss in the event that one of the services goes offline
or shuts down (\emph{S} capability).

In terms of trust violations, such ``secure'' cloud storage services
are being paid to store user data, disincentivizing implicit
violations. Compelled violations are also made difficult since the
third party provider lacks access to the client-side secrets necessary
to decrypt or modify the encrypted and authenticated data they
store. Due to the CA trust requirements that exists in such services'
sharing implementations, however, it is possible that such a service
could be compelled to mount a MitM attack on one of their users in
order to provide such data to the compelling party (similar to
government efforts to compel Apple to create a flawed version of OSX
that would be vulnerable to brute force
attacks~\cite{ars-cookvfbi}). Similarly, such a service could be
compelled to surrender their CA private key, allowing the compelling
party to take over the trusted CA role and mount such a MitM attack
themselves (similar to the how Lavabit was compelled to turn over
their private TLS keys to facilitate government access to the data
they controlled~\cite{levsion-lavabit}). Unintentional, Insider, and
Outsider violations are all similar to the traditional use case: such
violations are technically possible, but the third party at least has
a vested interest in avoiding such violations for reputation-related
reasons.

Furthermore, since services such as Tresorit are not open source or
widely audited by independent parties, the user must trust that the
code they are running to access such services is faithfully
implementing the security guarantees it such services claim to
support. It is possible that such a service could ship a flawed
version of their code due to a wide range of trust violations
(e.g. they could be compelled to ship such code, or it could be an
honest unintentional mistake).

A summary of the Tresorit trust model results are shown the
Tables~\ref{tab:trust:app:cap} and~\ref{tab:trust:app:threats}. Such a
service does more to mitigate third party trust and reduce the
likelihood of violations than a traditional cloud storage service, but
still leave room for improvement. SpiderOak~\cite{spideroak},
Wuala~\cite{wuala}, and related services have similar trust profiles
to Dropbox.

\subsection{Social Media}

Social media sites such as Facebook, Google Plus, etc have become
popular since the early 2000s. Such sites maintain a ``social-graph''
of connections between users, and facilitate communication and sharing
of pictures, events, and other data between users. Such sites are
generally free to users, and instead monetize user data and
interactions for the purpose of selling targeted advertising to
companies wishing to reach certain types of users. Given their
ubiquity in the modern Internet landscape, as well as their position
as ad-suppurated services, it's useful to evaluate modern Social Media
sites using my trust model. Facebook is the largest social media site
today, serving over 1.5 billion users as of 2015~\cite{foster2014}. As
such, I'll evaluate it as an example of the variety of social media
site available today.

In terms of capabilities, Facebook, like Dropbox and other traditional
cloud services, must be trusted with a full range of
capabilities. Facebook is responsible for faithfully storing user
data, Facebook can access and read all data it stores, Facebook can
manipulate the data it stores, and Facebook is capable of performing
meta-analysis of what data users are accessing and of how they are
accessing it.

In terms of likelihood of trust violations, Facebook differs a bit
from previously analyzed systems in that it's the first ad-support
systems I've discussed. This increases the likelihood of implicit
trust failures due to Facebook's business model being based around the
sale of user data. Indeed, and as mentioned in
Chapter~\ref{chap:challenges}, Facebook has a record of implicit trust
violations ranging from the Emotional Contagion Study~\cite{goel2014}
to its use of user's photos in the ads it
serves~\cite{mashable-socialads}. Beyond implicit trust violations,
Facebook's trust violation profile is again similar to other
traditional cloud services such as Dropbox. Like
Dropbox~\cite{dropbox-transparency}, Compelled violations are known to
occur~\cite{facebook-transparency}. Unintentional, insider, and
outsider violations are all possible, but Facebook has an active
interest in avoiding them. Collusion violations aren't really
applicable since Facebook is a single-party actor.

Tables~\ref{tab:trust:app:cap} and~\ref{tab:trust:app:threats} show a
summery of the Facebook trust model analysis. Google
Plus~\cite{google-plus}, and related services have similar trust
profiles to Facebook.

\subsection{Communications}

Communication systems ranging from email and chat to voice and video
calling are another popular modern use case. The privacy and security
of these systems are a matter of great public concern, and indeed many
of the current legal privacy and security battles revolve around the
ability to communicates in a private and secure manner
(e.g.~\cite{apple-fbiletter, greenwald-prism, levsion-lavabit}). It is
thus useful to apply my trust model to the analysis of several such
services. I'll analyze both traditional (Gmail) and secure (GPG/PGP)
email services as well as traditional (Google Hangouts) and secure
(TextSecure) chat applications. Tables~\ref{tab:trust:app:cap}
and~\ref{tab:trust:app:threats} show a summery of this analysis.

Gmail~\cite{google-gmail} and Hangouts~\cite{google-hangouts} are both
Google-hosted communication services - placing them fairly soundly in
the ``traditional cloud services'' camp. As such, their profiles are
similar to those of Dropbox and Facebook. Both services require
granting Google a full range of capabilities over user data. Like
Facebook, both services are ad-supported - increasing the likelihood
of implicit trust violations (although unlike Facebook, Google seems
to have a better track record of not committing such
violations). Similarly, both services are known to be subject to
compelled violations~\cite{google-transparency}\footnote{It's possible
  such cloud communication services are actually at an increased risk
  of compelled violations relative to other cloud services due to the
  existence of laws such as the Communications Assistance for Law
  Enforcement Act (CALEA)~\cite{calea-usc, calea-fcc} specifically
  designed to aid the government in obtaining a user's communications
  as well as the lowered standards law enforcement agencies are
  traditionally required to meet to access a user's digital
  communications as per the third party
  doctrine~\cite{scotus-usvmiller, scotus-smithvmaryland}.}, and are
disincentivized, although by no means immune, from committing
unintentional, insider, and outsider violations\footnote{Google has
  taken steps to ensure communication between all of its data centers
  and between mail servers are encrypted in transit, helping to
  minimize outsider
  violations~\cite{gmail-blog-encryption}. Similarly, it has recently
  started providing end users with information as to whether or not
  encrypted email transmission was possible and whether or not an
  email' sender has been authenticated~\cite{gmail-blog-indicators}.
  In both cases however, third parties, not end users, remain in full
  control of all the necessary encryption keys, limiting this
  protection to the mitigations of outsider violations, and doing
  little to mitigate implicit, compelled, unintentional, or insider
  violations.}. Thus, Google is able to analyze, alter, and expose any
data that travels across its network using either service - either of
it's own volition or due to a compelled order or unauthorized data
breach.

The OpenPGP protocol~\cite{callas2007} is one of the traditional
mechanisms for securing digital communications. It is most widely used
with email - and is implemented in a wide variety of applications from
desktop apps such as GnuPG (GPG)~\cite{gnupg} to browser-based plugins
such as Mailvelope\cite{mailvelope}. The OpenPGP protocol utilizes
public-key cryptography to end-to-end encrypt and authenticate
messages traveling across untrusted mediums. It can be applied atop
mail traversing traditional email systems such as Gmail as well as to
messages traversing chat applications such as Google Hangouts. When
used with such service, PGP provides an additional level of trust
mitigation above and beyond what is possible to achieve via the native
services themselves. In terms of trusted capabilities, a user
employing PGP atop a traditional third party cloud service such as
Gmail minimizes both the third party's access (via encryption) and
manipulation (via authentication) capabilities. In such a scenario
only the end-users involved in a given communication, and not any
third party through which that communication might pass, have access
to the necessary cryptographic keys required to read or alter the
message. The third party, however, is may still capture metadata about
the communication since such metadata is outside of the scope of the
message content that PGP is capable of securing. The third party is
also still capable of dropping or deleting the communication all
together, and thus still poses the ``storage'' capability.

Since PGP isn't controlled by any single third party, there is no
straightforward analysis of its likelihood of PGP-related trust
violations. Thus, it does not make sense to discuss the likelihood of
implicit or compelled PGP violations. PGP can certainly aid in
mitigating the effects of such violations by other third parties since
it limits the capabilities of such parties as discussed above, but the
likelihood of such violations by those that create PGP-based apps
themselves is not readily analyzable. Most PGP implementations are,
however, open source. This helps to mitigate (although not necessarily
prevent, e.g.~\cite{heartbleed}) unintentional, insider, and outsider
violations by maximizing the number of eyes on the code and reducing
the likelihood of mistakes or intentionally coded vulnerabilities and
back doors. And since PGP effectively limits the available
capabilities, even if a trust violation occurs, the likelihood of such
a violation resulting in a successful exposure of user data is low.

Due to the numerous challenges and deficiencies associated with using
OpenPGP-based systems~\cite{green-pgp}, developers have created a
number of alternate secure communication protocols. These protocols
aim to provide forward-security, metadata privacy, deniability,
contact authentication, and message encryption and authentication for
(primarily) real-time communication such as instant messaging and chat
systems. Examples of such protocol include OTR~\cite{otr-v3} and
OTR-derived protocols like TextSecure~\cite{otr-advanced-ratchet}. The
TextSecure protocol is used by several apps such Open Whisper System's
Signal~\cite{openwhisper} and WhatsApp~\cite{whatsapp}. TextSecure is
thus a useful target to analyze under my trust framework.

TextSecure is an OTR-derived asynchronous secure messaging
protocol. It uses various forms of asymmetric cryptography to provide
users with end-to-end encrypted and authenticated individual and group
message capabilities. TextSecure has been formally analyzed and proven
to provide secure encryption and message
authentication~\cite{frosch2014}. Use of TextSecure thus denies any
third party through which TextSecure message might pass (including the
TextSecure server itself) the access or manipulation
capabilities. Furthermore, TextSecure makes efforts to secure all
metadata from non-participating actors as the server itself. This
strongly curtails a third party's ability to analyze message
metadata. It is still possible for a network-level adversary or the
TextSecure server to discover the raw network (e.g. IP) endpoints
involved in a TextSecure exchange, but higher level details are not
available. It's also possible to couple TextSecure with existing
network anonymity systems such as Tor to mitigate such network-level
meta-analysis~\cite{intercept-chatting}. TextSecure users are still
dependent on a third party to operate a TextSecure server in order to
communicate in the first place (e.g. it's not a fully distributed
protocol), but beyond this ``storage''-like capability, TextSecure
almost no other capabilities to any third party.

Like OpenPGP, TextSecure is a protocol implemented by several
different apps. Such application providers (e.g. Open Whisper Systems)
specifically market their products as being a secure alternative to
more traditional chat systems, and thus are strongly dissuaded from
committing any kind of implicit or compelled trust
violation. Furthermore, most TextSecure implications are open source,
which mitigates the likelihood of unintentional\footnote{Researchers
  have discovered bugs in TextSecure, but these bugs were quickly
  patched~\cite{frosch2014}.}, insider, or outsider
violations. TextSecure has also undergone external audits and reviews,
further decreasing the likelihood of an unintentional or insider
violation~\cite{frosch2014}. As in OpenPGP, even if a violation
occurred, the capability restrictions discussed above severely limit
what data the violation would expose. TextSecure thus represents a
successful effort to reduce third party trust exposure and secure user
comm unctions.

\subsection{Password Managers}

Probably the most common existing variant of a ``secret storage''
system is manifest by consumer-oriented password management
programs. Such programs are useful for helping end-user remember
passwords, and by extension, for encouraging users to use stronger
(i.e. longer and/or more random) passwords~\cite{brodkin-passman,
  krebs-passwords, schneier-passwords}. It's thus useful to evaluate
the trust model surrounding such programs. LastPass~\cite{lastpass} is
one of the most popular cloud-based password managers. I'll thus apply
my trust model to a typical LastPass deployment. The results are
summarized in Tables~\ref{tab:trust:app:cap}
and~\ref{tab:trust:app:threats}.

LastPass operated by storing encrypted user passwords on a
LastPass-controlled server. Passwords are encrypted on the client and
only encrypted passwords are sent to Dropbox. Each password is
encrypted using a key derived from a user-supplied ``master''
password. LastPass never stores this master password, making it
difficult for them to decrypt the encrypted data they store. Thus,
LastPass limits it's ability ``access'' user data. LastPass does not,
however, appear to perform any kind of cryptographic authentication on
the data it stores, meaning it still has full capabilities over the
``manipulation'' capability.\footnote{In realty, it is likelihood
  somewhat difficult for LastPass to modify user data intelligently
  since they lack the ability to read the result of their
  modifications. None the less, the lack of any client-side
  cryptographic protections against modification leaves the door open
  to a range of potential attack on LastPass's client side encryption,
  as per the ``cryptographic doom''
  principle~\cite{marlinspike-doom}.}  Similarly, LastPass is fully
reasonable for faithfully storing user data and and full access to all
user metadata associated with the password they store on LastPass.

In terms of likelihood of trust violations, LastPass has a very
similar profile to a service like Tresorit. LastPass is a ``freemium''
service that generates it's income off it's ability to faithfully
store and protect user password. This disincentivizes implicit trust
violations. LastPass also has a strong incentive to minimize (at least
public) compelled violations, although it is still subject to such
violations. Unintentional violations are similar disincentivized,
although they have occurred
before~\cite{lastpass-blog-breach}. Insider and outsider violations
are also disincentivized.

Like Tresorit, LastPass is not open source nor subject to public code
audits. As such, the user is required to trust the LastPass has
faithfully coded it's software not to expose additional capabilities
via hidden back doors. It is thus possible that LastPass could be
compelled to modify the LastPass client program to do something like
sending copies of a user's master password back to LastPass where they
could be used to decrypt all of the user data. It's also possible that
the lack of cryptographic authentication on user data would allow
LastPass to mount a range of attacks on a user - potentially revealing
one or more of the passwords they store with LastPass in the process.

\subsection{Cloud Infrastructure Services}

EC2

\subsection{SSaaS Alternatives}

Base Secret Storage (Hashcorp's Vault)

Shared Secret Storage

%%  LocalWords:  SSaaS FISC SSP CMAC OneDrive Tresorit Desincent MitM
%%  LocalWords:  SpiderOak Wuala Lavabit LastPass CALEA Hashcorp's
%%  LocalWords:  Mailvelope TextSecure OTR WhatsApp LastPass's
%%  LocalWords:  freemium
