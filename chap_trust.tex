\chapter{An Issue of Trust}
\label{chap:trust}

Trust and privacy are closely related qualities in
computing~\cite{flowerday2006}. Can we maintain our digital privacy
without having to trust anyone? We can imagine scenarios that maintain
privacy without trust, but they generally involve only storing data on
self-designed, built, and programmed devices that never leave our
possession. Such arrangements are, at best, impractical for the vast
majority of users, and at worst, simply not possible to achieve
today. The range of manufactures, suppliers, and service providers
inherent in the modern computing landscape require that we make
decisions regarding whom to trust at every step of any digital
interaction in which we partake.

The cloud computing model, by its very nature, further amplifies the
number of parties we must trust. But what does it mean to trust a
third party in the cloud? Before discussing the details of an SSaaS
ecosystem, it's helpful to further define ``trust''. In this chapter,
I define a model for analyzing trust and apply this model to compare
various traditional software and technology deployments to SSaaS-backed
options.

\section{Analyses Framework}
\label{chap:trust:framework}

Generally, when we use modern computing devices and services, we must
trust third-party manufactures and service providers with our
data. The manner in which this third party trust relates to the
privacy of user data has two main factors: how much trust do we place
in third parties (e.g. how much of our personal data do we grant them
access to), and in what manner can they violate this trust (e.g. how
can they abuse the access they are granted). I will thus evaluate
computing trust models across two main axes: the \emph{degree} of
trust we must place in third parties, and the manner in which this
trust might be \emph{violated}. Our ideal trust model for a given use
case will minimize the degree of third party trust while also
minimizing the likelihood that such trust will be violated.

In terms of degrees of trust, we can entrust third parties with the
following data-related capabilities:

\begin{packed_desc}
\item[Storage (S):] \hfill \\
  Can a third party faithfully store private user data and make it
  available to the user upon request? Misuse of this capability may
  result in a loss of user data, but won't generally result in the
  exposure of user data.
\item[Access (R):] \hfill \\
  Can a third party read and interpret the private user data they
  store? Misuse of this capability may result in the exposure of user
  data.
\item[Manipulation (W):] \hfill \\ Can a third party modify the
  private user data to which they have access? Misuse of this
  capability may result in the ability to manipulate a user
  (e.g. changing appointments on a user's calendar, etc).
\item[Meta-analysis (M):] \hfill \\
  Can a third party gather user metadata related to any stored private
  user data? Misuse of this capability may result in the ability to
  infer private user data (e.g. who a user is friends with based on
  data sharing patterns).
\end{packed_desc}

I'll define a trust violation as occurring when a third party
exercises any of the above capabilities without explicit user
knowledge and permission. Put another way, a trust violation occurs
whenever a third party leverages a capability with which they are
entrusted in a manner in which the user does not expect the capability
to be leveraged.

I define several types of trust violations based on the manner in
which the violation occurs and the motivations behind it:

\begin{packed_desc}
\item[Implicit (P):] \hfill \\
  This class of trust violation occurs when a third party violates a
  user's trust in a manner approved by the third party. An example
  might be sharing user data with a business partner (e.g. an
  advertiser). Often these forms of violations aren't really
  ``violations'' in the sense that a user may have clicked though a
  Terms of Service agreement that granted implicit permission for such
  use, but if the third party is engaging in behavior that the user
  would not generally expect, an implicit trust violation has
  occurred.
\item[Compelled (C):] \hfill \\
  This class of trust violation occurs when a third party is compelled
  by another actor to violate a user's trust. The most common example
  would be a third party being forced to turn over user data or
  records in response to a request from the government with
  jurisdiction over the party.
\item[Unintentional (U):] \hfill \\
  This form of violation occurs when a third party unintentionally
  discloses or manipulates user data. An example would be a coding
  error that allows either the loss of or unfettered access to user
  data.
\item[Insider (I):] \hfill \\
  This class of violation occurs when a privileged adversary within
  the third party violates a user's trust without the permission or
  knowledge of the third party. An example would be a cloud service
  provider employee accessing or disclosing private user data without
  authorization.
\item[Outsider (O):] \hfill \\
  This class of violation occurs when an external adversary gains
  unauthorized access to private user data stored by third party. An
  example would be an adversary exploiting a bug in a third party's
  authorization infrastructure to gain unauthorized access to user
  data.
\end{packed_desc}

\section{Traditional Model}
\label{chap:trust:traditional}

\begin{figure}[t]
  \centering
  \includegraphics[height=175px]{./figs/out/TrustModel-Traditional.pdf}
  \caption{Traditional Trust Model}
  \label{fig:trust-traditional}
\end{figure}

Existing cloud services are not generally well optimized for
maximizing user privacy. Such services tend to apply an all-or-nothing
trust model where a user must seed a high degree of trust to each
service in order to reap the benefits each service provides. Figure
\ref{fig:trust-traditional} shows the basic trust-for-features
relationship between a user, their private data, and a traditional
cloud service provider.

We can analyze the Dropbox example from \S~\ref{chap:intro:example}
using my proposed framework. To begin, what capabilities is a normal
Dropbox user entrusting to Dropbox? Clearly, users must trust Dropbox
to faithfully store their data since that is Dropbox's core purpose,
so we have granted Dropbox the \emph{S} capability. Furthermore users
must also grant Dropbox the ability to read and access their data
(i.e. the \emph{R} capability) in order to support Dropbox's sharing
and syncing features. While Dropbox doesn't generally utilize it,
users are also effectively granting the manipulation (\emph{W})
capability as well since the user has no mechanisms for ensuring that
Dropbox can't manipulate their data. Finally, Dropbox has full access
to user metadata related to their usage of the service, granting them
the \emph{M} capability. Thus, Dropbox users must trust Dropbox with
all possible capabilities.

But how likely is it that Dropbox might misuse any of these
capabilities, thus violating the user's trust and privacy? In terms of
implicit violations (\emph{I}), Dropbox charges users for storage, and
thus shouldn't generally rely on reading or sharing user data for
advertising purposes. Furthermore, such a business model relies on
Dropbox remaining in its paying users' good graces, disincentivizing
potentially questionable behavior. None the less, there is evidence of
Dropbox opening user files for unknown
reasons~\cite{vintsurf-dropbox}, which might indicate a possible
\emph{I} violation. The user has no way to prevent an \emph{I}
violation when using Dropbox, so we can do no more than give Dropbox
the benefit of the doubt in this area.

In terms of compelled (\emph{C}) violations, Dropbox is a US-based
company, and is thus susceptible to a variety of government-sponsored
data requested, from subpoenas issued under the Third Party
Doctrine~\cite{thompson-thirdparty}, to probable cause search
warrants~\cite{us-constitution-amend4}, to National Security
Letters~\cite{fbi-nsl}, to FISC~\cite{fisc} orders. Dropbox publishes
a transparency report~\cite{dropbox-transparency} indicating how
frequently they are compelled to violate user privacy. Recent versions
of this report indicate that Dropbox receives a few hundred requests
for various user data every 6 months.

Unintentional (\emph{U}), Insider (\emph{I}), or Outsider (\emph{O})
violations are all possibilities when using Dropbox. On the \emph{U}
front, Dropbox had an incident in 2011 that allowed anyone to log into
the service using any password for a 5 hour
period~\cite{dropbox-authbug}. Thus far, Dropbox appears to have
avoided any \emph{I}-type violations, but it has been the target of
various \emph{O}-type attempted violations, primarily built around
advisories who obtain common user
passwords~\cite{dropbox-passwords}. Needless to say, while Dropbox
works to avoid these kinds of violations, they are certainly still
possible, have occurred in the past, and may well occur in the future.

As we can see, a traditional cloud service like Dropbox currently
requires an essentially full degree of user trust (i.e. \emph{S},
\emph{R}, \emph{W}, and \emph{M} capabilities) while also being
susceptible to a full range of trust violations (e.g. \emph{P},
\emph{C}, \emph{U}, \emph{I}, and \emph{O} type violations). Dropbox
is not unique. Other modern computing services from social media
sites, to file lockers, to communication systems all suffer from the
same high-trust, high potential for violations paradigm.

\section{SSaaS Model}
\label{chap:trust:ssaas}

\begin{figure}[t]
  \centering
  \includegraphics[height=175px]{./figs/out/TrustModel-Seperated.pdf}
  \caption{SSaaS Trust Model}
  \label{fig:trust-ssaas}
\end{figure}

In order to enhance user privacy in the cloud, we must move beyond the
traditional full-trust, easily violated model presented in
\S~\ref{chap:trust:traditional}. Of the two components of my trust
framework, degree of trust and potential for violation, degree is the
easier to control quality: what capabilities to trust a cloud provider
with is largely within the user's control, where as the method in
which trust might be violated is largely outside of a user's
control. I will thus focus my solution on mitigating degree of trust
first while disincentivizing methods of violation second.

The ideal trust model begins with the principle of least
privilege~\cite{saltzer1975}: we should only afford a cloud provider
the minimal degree of trust necessary to provide the intended
features. Furthermore, in order to monitor cloud providers for
potential trust violations, we would also like to maintain some degree
of auditing over any capability we entrust to a provider. Minimal,
audited trust is the basis of my ideal trust model.

Applying this ideal trust model to the previous Dropbox example, I
conclude that Dropbox should really only be afforded the storage
(\emph{S}) capability: after all, there is no real need for Dropbox to
ever be able to access (\emph{R}) or manipulate (\emph{W}) user data
in order to blindly sync files across device or share them with other
users. While Dropbox does not need the metadata (\emph{M}) capability
to simply support the desired user case, it is far more difficult for
the user to limit this capability then the \emph{R} or \emph{W}
capabilities. I thus will also concede this capability to Dropbox as
well. We have thus reduced Dropbox's capabilities from four (full
trust) to two (minimal trust).

But how can we enforce this limited trust profile when using Dropbox?
Figure~\ref{fig:trust-ssaas} shows my proposed SSaaS solution to this
problem. I introduce a new actor: the Secret Storage Provider (SSP)
into the mix. I then restrict the user to only storing encrypted and
authenticated data with Dropbox. The user stores the associated
encryption and verification keys with the SSP. Assuming we utilize
strong encryption and integrity systems like AES~\cite{nist2001} +
CMAC~\cite{dworkin2005}, Dropbox can not feasibly decrypt and access
the user's data nor can they manipulate user data without
detection. Storing the keys with an SSP, as opposed to simply forcing
the user to maintain them manually, has a number of benefits: namely,
it affords users continued support for simple sharing and syncing use
cases. As long as the user's Dropbox client can communicate with the
SSP from any location where they can also communicate with Dropbox,
the user can continue to utilize Dropbox as they traditionally would,
but with significantly less trust in Dropbox itself.

But have we simply replaced one third party with another? Why is the
SSP any more trustworthy than Dropbox itself? There are several reason
why we might expect an SSP to be less prone to trust violations then a
feature provider like Dropbox. I'll discuss these in
\S\ref{chap:ssaas}. But in terms of degrees of trust, we really aren't
affording the SSP any greater degree of trust then Dropbox. Both are
entrusted with the \emph{S} and \emph{M} capabilities, but neither has
the \emph{R} or \emph{W} capability: Dropbox has limited capabilities
because it only holds encrypted and authenticated user data, and the
SSP has limited capabilities because it holds no direct user data at
all, only the cryptographic keys used to protect such data. As long as
the SSP faithfully guards the secret keys they store, the trust model
holds. There are a few new risks in the SSaaS model, however. If both
the feature provider (e.g. Dropbox) and the SSP are located in the
same regulatory jurisdiction, it may still be possible for a single
entity to compel (\emph{C}-type violation) them both or provide data
that would allow an adversary to elevate their capabilities to include
\emph{R} and \emph{W}. Likewise, if Dropbox and the SSP collude to
violate a user's trust, a similar capability elevation will
occur. This latter point introduces a new violation type into my
framework:

\begin{packed_desc}
\item[Colluding (L):] \hfill \\ This class of violation occurs when
  multiple partially-trusted parties collude to gain capabilities over
  user data beyond what the user intended each individually to
  have. An example would be an SSP sharing the user's encryption keys
  with the feature provider storing the corresponding encrypted data.
\end{packed_desc}

This framework provided a basis for analyzing third party trust as
well as the basic argument in favor of SSaaS as a trust-reducing
system. I discuss SSP trust and violation mitigation further in
Chapter~\ref{chap:ssaas}.

\section{Trust Survey of Existing Systems}
\label{chap:trust:survey}

In order to evaluate the trust and security of the SSaaS ecosystem,
it's useful to apply this trust model to a number of existing
scenarios. Table~\ref{tab:trust:app:cap} shows a summery of the
capabilities granted to third parties across a number of common
applications. Table~\ref{tab:trust:app:threats} shows known and likely
threats posed by third parties across the same range of
applications. Each of these applications is discussed in more depth
below.

\begin{table}[!th]
  \footnotesize
  \centering
  \tabulinesep = 2pt
  \begin{tabu} to \textwidth
    { | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | }
    \hline
    \textbf{Application}
    & \textbf{Storage}
    & \textbf{Access}
    & \textbf{Manipulation}
    & \textbf{Meta-analysis}
    \\ \hline
    Dropbox
    & Full
    & Full
    & Full
    & Full
    \\ \hline
    Tresorit
    & Full
    & Partial
    & Partial
    & Full
    \\ \hline
    Facebook
    & Full
    & Full
    & Full
    & Full
    \\ \hline
  \end{tabu}
  \caption{Third Party Trust Capabilities}
  \label{tab:trust:app:cap}
\end{table}

\begin{table}[!th]
  \footnotesize
  \centering
  \tabulinesep = 2pt
  \begin{tabu} to \textwidth
    { | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | X[1,c,m]
      | }
    \hline
    \textbf{Application}
    & \textbf{Implicit}
    & \textbf{Compelled}
    & \textbf{Unintended}
    & \textbf{Insider}
    & \textbf{Outsider}
    & \textbf{Colluding}
    \\ \hline
    Dropbox
    & Desincent.
    & Vulnerable
    & Desincent.
    & Desincent.
    & Desincent.
    & N/A
    \\ \hline
    Tresorit
    & Desincent.
    & Minimal
    & Desincent.
    & Desincent.
    & Desincent.
    & N/A
    \\ \hline
    Facebook
    & Vulnerable
    & Vulnerable
    & Desincent.
    & Desincent.
    & Desincent.
    & N/A
    \\ \hline
  \end{tabu}
  \caption{Third Party Trust Violations}
  \label{tab:trust:app:threats}
\end{table}

\subsection{Cloud File Storage}

As mentioned, cloud file storage is a popular third party use
case. I've discussed Dropbox~\cite{dropbox} as an example cloud
storage provider extensively in the earlier sections of this
chapter. A summery of the Dropbox trust model results are shown the
Tables~\ref{tab:trust:app:cap} and~\ref{tab:trust:app:threats}. As
previously concluded, Dropbox both requires a full range of trusted
capabilities and is susceptible to a full range of violations this
trust. Google Drive~\cite{google-drive}, Microsoft
OneDrive~\cite{microsoft-onedrive}, and related services have similar
trust profiles to Dropbox.

As discussed in Chapter~\ref{chap:related}, a number of systems have
been developed with the aim of overcoming the trust challenges. These
systems include ``end-to-end'' encrypted file storage serves such as
Tresorit~\cite{tresorit}. These systems aim to place limits on a their
own ability to leverage the access (\emph{R}) capability through the
use of client-side encryption. Likewise, they aim to limit their
access to the manipulation (\emph{W}) capability through client-side
data authentication. In the base case where a user merely wishes to
store data on a single device and not share it with others, these
systems are fairly successful in achieving their desired trust
mitigations. In order to sync data across multiple devices using such
systems, a user must manually provide some secret (e.g. a password,
etc) on each device to bootstrap its operation. While potentially
burdensome and inconvenient, this practice is in line with these
services trusted capabilities mitigation since ti does not require any
additional third party trust.

The place where these systems falter at mitigating third party trust
is via their support for multi-user sharing and collaboration. Such
services tend to accomplish multi-user sharing by acting as a trusted
certificate authority (CA) in charge of issuing user
certificates\footnote{A certificate is a combination of a user's
  public key combined with certain metadata and signed by a trusted
  issuers. See Section~\ref{chap:background:crypto} for more
  information.} These certificates are then used with various
asymmetric cryptographic primitives (e.g. RSA~\cite{rivest1978}) to
exchange the necessary secrets between users and bootstrap secure
multi-user sharing. Unfortunately, as a trusted CA, these services are
capable of issuing fraudulent user certificates to themselves or other
parties. This allows them to mount man-in-the-middle (MitM) attacks on
any user trying to share data by impersonating other users utilizing
the services. This define is discussed in depth at~\cite{wilson2014},
and leads to a breakdown of their claim that their users need not
trust such service providers themselves, at least when employing
multi-user sharing. By mounting a MitM attack on a user trying to
share data with another user, such service providers can regain the
\emph{R} and \emph{W} capabilities they claim not to
have. Furthermore, these services do little to mitigate their access
to metadata (\emph{M} capability). Nor do they provide ways for
users to avoid data loss in the event that one of the services goes
offline or shuts down (\emph{S} capability).

In terms of trust violations, such ``secure'' cloud storage services
are being paid to store user data, disincentivizing implicit
violations. Compelled violations are more difficult since the third
party provider lacks aces to the client-side secrets necessary to
decrypt or modify the encrypted and authenticated data they store. Due
to the trust-whole that exists in such services sharing
implementations, however, it is possible that such a service could be
compelled to mount a MitM attack on a user sharding data in order to
provide such data to the compelling party (similar to government
efforts to compel Apple to create a flawed version of OSX that would
be vulnerable to brute force attacks~\cite{ars-cookvfbi}). Similarly,
such a service could be compelled to surrender their CA private key,
allowing the compelling party to take over their CA role and mount
such a MitM attack themselves (similar to the how Lavabit was
compelled to turn over their private TLS keys to facilitate government
access to the data they
controlled~\cite{levsion-lavabit}). Unintentional, Insider, and
Outsider violations are all similar to the traditional use case: such
violations are technically possible, but the third party at least has
a vested interest in avoiding such violations for reputation-related
reasons.

A summary of the Tresorit trust model results are shown the
Tables~\ref{tab:trust:app:cap} and~\ref{tab:trust:app:threats}. Such a
service does more to mitigate third party trust and reduce the
likelihood of violations than a traditional cloud storage service, but
still leave room for improvement. SpiderOak~\cite{spideroak},
Wuala~\cite{wuala}, and related services have similar trust profiles
to Dropbox.

\subsection{Social Media}

Social media sites such as Facebook, Google Plus, etc have become
popular since the early 2000s. Such sites maintain a ``social-graph''
of connections between users, and facilitate communication and sharing
of pictures, events, and other data between users. Such sites are
generally free to users, and instead monetize user data and
interactions for the purpose of selling targeted advertising to
companies wishing to reach certain types of users. Given their
ubiquity in the modern Internet landscape, as well as their position
as ad-suppurated services, it's useful to evaluate modern Social Media
sites using my trust model.

Facebook is the larger social media site today, serving over 1.5
billion users as of 2015~\cite{foster2014}. As such, I'll evaluate it
as an example of the variety of social media site available today.

In terms of capabilities, Facebook, like Dropbox and other traditional
cloud services, must be trusted with a full range of trusted
capabilities. Facebook is responsible for faithfully storing user
data, Facebook can access and read all data it stores, Facebook can
manipulate the data it stores, and Facebook is capable of performing
meta-analysis what data users are accessing and of how they are
accessing it.

In terms of likelihood of trust violations, Facebook differs a bit
from previously analyzed systems in that it's the first ad-support
systems I've discussed. This increases the likelihood of implicit
trust failures due to Facebook's business model being based around the
sale of user data. Indeed, and as mentioned in
Chapter~\ref{chap:challenges}, Facebook has a record of implicit trust
violations ranging from the Emotional Contagion Study~\cite{goel2014}
to its use of user's photos in the ads it
serves~\cite{mashable-socialads}. Beyond implicit trust violations,
Facebook's trust violation profile is again similar to other
traditional cloud services such as Dropbox. Compelled violations are
possible, Unintentional, insider, and outsider violations are all
possible, but Facebook has an active interest in avoiding them, and
collusion violation aren't really applicable since Facebook is a
single-party actor.

Tables~\ref{tab:trust:app:cap} and~\ref{tab:trust:app:threats} show a
summery of the Facebook trust model analysis. Google
Plus~\cite{google-plus}, and related services have similar trust
profiles to Facebook.

\subsection{Communications}

Gmail
WhatsApp
GnuPG

\subsection{Password Managers}

LastPass

\subsection{Cloud Infrastructure Services}

EC2

\subsection{SSaaS Alternatives}

Base Secret Storage (Hashcorp's Vault)

Shared Secret Storage

%%  LocalWords:  SSaaS FISC SSP CMAC OneDrive Tresorit Desincent MitM
%%  LocalWords:  SpiderOak Wuala Lavabit
